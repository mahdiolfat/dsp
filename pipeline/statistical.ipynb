{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import scipy.signal as sps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convm(x, p):\n",
    "    '''Convolution Matrix\n",
    "    (N + p - 1) by p non-symmetric Toeplitz matrix\n",
    "    '''\n",
    "\n",
    "    if p < 1:\n",
    "        raise ValueError(f\"p must be greater or equal to 1.\")\n",
    "\n",
    "    N = len(x) + 2 * p - 2\n",
    "    # the signal centered over its support\n",
    "    # needed for the signal information-preserving frequency spectrum\n",
    "    xcol = (x.copy()).reshape(-1, 1)\n",
    "    xpad = np.concatenate((np.zeros((p-1, 1)), xcol, np.zeros((p-1, 1))))\n",
    "    X = np.empty([len(x) + p - 1, p])\n",
    "    for i in range(p):\n",
    "        X[:, i] = xpad[p - i - 1:N - i,0]\n",
    "    return X\n",
    "\n",
    "def covar(x, p):\n",
    "    '''Covariance Matrix\n",
    "    p x p hermitian toeplitz matrix of sample covariances\n",
    "    '''\n",
    "\n",
    "    m = len(x)\n",
    "    # remove the mean\n",
    "    x0 = x.copy() - np.mean(x)\n",
    "    R = np.transpose((convm(x0, p + 1).conjugate())) @ (convm(x0, p + 1) / (m - 1))\n",
    "    return R\n",
    "\n",
    "def back_substitution(x, p):\n",
    "    '''Convinient recursion for an all-pole model.'''\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 4)\n",
      "[[1. 0. 0. 0.]\n",
      " [3. 1. 0. 0.]\n",
      " [2. 3. 1. 0.]\n",
      " [0. 2. 3. 1.]\n",
      " [0. 0. 2. 3.]\n",
      " [0. 0. 0. 2.]]\n",
      "x=array([1, 3, 2])\n",
      "(5, 5)\n",
      "[[ 1.  -0.5  0.   0.   0. ]\n",
      " [-0.5  1.  -0.5  0.   0. ]\n",
      " [ 0.  -0.5  1.  -0.5  0. ]\n",
      " [ 0.   0.  -0.5  1.  -0.5]\n",
      " [ 0.   0.   0.  -0.5  1. ]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 3, 2])\n",
    "p = 4\n",
    "X = convm(x, p)\n",
    "print(X.shape)\n",
    "print(X)\n",
    "print(f\"{x=}\")\n",
    "R = covar(x, p)\n",
    "print(R.shape)\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determinist Signal Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pade(x, p, q):\n",
    "    '''\n",
    "    Reference Page 138, Table 4.1\n",
    "    The Pade approximation models a signal as the unis sample response\n",
    "    of linear shift invariant system have p poles and q zeros.\n",
    "    '''\n",
    "    if p + q > len(x):\n",
    "        raise ValueError(f\"Model order {p + q} is too large.\")\n",
    "\n",
    "    X = convm(x, p + 1)\n",
    "\n",
    "    # Linear difference matrix spanning the number of zeros\n",
    "    Xq = X[q + 1:q + p + 1, 1:p + 1].copy()\n",
    "    print(Xq.shape)\n",
    "    a = np.linalg.solve(-Xq, X[q + 1: q + p + 1, 0])\n",
    "    # a(0) normalized to 1\n",
    "    a = np.concatenate((np.ones(1), a)).reshape(-1, 1)\n",
    "    b = X[:q + 1, :p + 1] @ a\n",
    "\n",
    "    return (a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "(0, 0)\n",
      "(1, 1)\n",
      "(array([[ 1. ],\n",
      "       [-1.5],\n",
      "       [ 1.5]]), array([[1.]]))\n",
      "(array([[1.]]), array([[1.  ],\n",
      "       [1.5 ],\n",
      "       [0.75]]))\n",
      "(array([[ 1. ],\n",
      "       [-0.5]]), array([[1.],\n",
      "       [1.]]))\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 1.5, 0.75, 0.375, 0.1875, 0.0938])\n",
    "\n",
    "x20 = pade(x, 2, 0)\n",
    "x02 = pade(x, 0, 2)\n",
    "x11 = pade(x, 1, 1)\n",
    "\n",
    "print(x20)\n",
    "print(x02)\n",
    "print(x11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_prony(x, p, q):\n",
    "    pass\n",
    "\n",
    "def prony(x, p, q):\n",
    "    '''\n",
    "    Least square minimization of poles to get denominator coefficients.\n",
    "    Solves directly (Pade method) to get numerator coefficients.\n",
    "    Also calculates minimum error achieved.\n",
    "    '''\n",
    "\n",
    "    if p + q > len(x):\n",
    "        raise ValueError(f\"Model order {p + q} is too large.\")\n",
    "\n",
    "    # copy and make given signal column array\n",
    "    X = convm(x, p + 1)\n",
    "    print(X.shape)\n",
    "    M = p + q\n",
    "    N = len(x)\n",
    "    print(f\"{N=}\")\n",
    "    xc = x.copy().reshape(-1, 1)\n",
    "\n",
    "    #Xq = X[q + 1:q + p + 1, 1:p + 1].copy()\n",
    "    #a = np.linalg.solve(-Xq, X[q + 1: q + p + 1, 0])\n",
    "    #a = np.concatenate((np.ones(1), a)).reshape(-1, 1)\n",
    "    #b = X[:q + 1, :p + 1] @ a\n",
    "\n",
    "    # the factorization does not guarantee nonsingularity!\n",
    "    # resulting matrix is positive *semi*-definite: all zeros are\n",
    "    # on/inside the unit circle\n",
    "    Xq = X[q:N + p - 1, :p].copy()\n",
    "    Xq1 = X[q + 1:N + p, 0].copy()\n",
    "    Xq_H = Xq.conjugate().transpose()\n",
    "    rx = Xq_H @ Xq1\n",
    "    Xinv = np.linalg.inv(Xq_H @ Xq)\n",
    "    a = -Xinv @ rx\n",
    "    print(a.shape)\n",
    "    # a(0) normalized to 1\n",
    "    a = np.concatenate((np.ones(1), a)).reshape(-1, 1)\n",
    "    # same as Pade method\n",
    "    b = X[:q + 1, :p + 1] @ a\n",
    "\n",
    "    # the minimum squared error\n",
    "    err = np.transpose(xc[q + 1:N]) @ X[q + 1:N, :p + 1] @ a\n",
    "\n",
    "    return a, b, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 2)\n",
      "N=21\n",
      "(1,)\n",
      "x=array([[ 1.  ],\n",
      "       [-0.95]])\n",
      "x=array([[1.  ],\n",
      "       [0.05]])\n",
      "x=array([[0.95]])\n"
     ]
    }
   ],
   "source": [
    "sig = np.ones(21)\n",
    "res = prony(sig, 1, 1)\n",
    "for x in res: print(f\"{x=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0637 -0.     -0.1061  0.      0.3183  0.5     0.3183  0.     -0.1061\n",
      " -0.      0.0637]\n",
      "(86, 6)\n",
      "N=81\n",
      "(5,)\n",
      "[[ 1.    ]\n",
      " [-1.9093]\n",
      " [ 2.374 ]\n",
      " [-1.9531]\n",
      " [ 1.035 ]\n",
      " [-0.2893]]\n",
      "[[ 0.0637]\n",
      " [-0.1216]\n",
      " [ 0.045 ]\n",
      " [ 0.0783]\n",
      " [ 0.1323]\n",
      " [ 0.081 ]]\n"
     ]
    }
   ],
   "source": [
    "# Shannon\n",
    "# poissons\n",
    "# autocorrs\n",
    "# gaussians\n",
    "# diracs\n",
    "\n",
    "N = 81\n",
    "N2 = (N - 1) // 2\n",
    "#t = np.linspace(-N2, N2, N)\n",
    "t = np.arange(N) - 5\n",
    "isys = 0.5 * np.sinc(t / 2)\n",
    "print(isys[:11].round(4))\n",
    "\n",
    "res = prony(isys, 5, 5)\n",
    "print(res[0].round(4))\n",
    "print(res[1].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 2)\n",
      "N=21\n",
      "(1,)\n",
      "a.transpose().ravel()=array([ 1.  , -0.95])\n",
      "G0.shape=(21, 2)\n",
      "x.shape=(21,)\n",
      "Ginv.shape=(2, 2)\n",
      "a=array([[ 1.  ],\n",
      "       [-0.95]])\n",
      "b=array([[1.        ],\n",
      "       [0.48542157]])\n",
      "err=1\n",
      "(86, 6)\n",
      "N=81\n",
      "(5,)\n",
      "a.transpose().ravel()=array([ 1.        , -1.90933949,  2.37404932, -1.95305779,  1.0349931 ,\n",
      "       -0.28932854])\n",
      "G0.shape=(81, 6)\n",
      "x.shape=(81,)\n",
      "Ginv.shape=(6, 6)\n",
      "(array([[ 1.        ],\n",
      "       [-1.90933949],\n",
      "       [ 2.37404932],\n",
      "       [-1.95305779],\n",
      "       [ 1.0349931 ],\n",
      "       [-0.28932854]]), array([[ 0.06366198],\n",
      "       [-0.12278121],\n",
      "       [ 0.04903531],\n",
      "       [ 0.07290069],\n",
      "       [ 0.13450599],\n",
      "       [ 0.08350918]]), 1)\n"
     ]
    }
   ],
   "source": [
    "def shanks(x, p, q):\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    N = len(x)\n",
    "    if p + q >= N:\n",
    "        raise ValueError(f\"Model order {p + q} is too large.\")\n",
    "\n",
    "    a, _, _ = prony(x, p, q)\n",
    "    print(f\"{a.transpose().ravel()=}\")\n",
    "    u = np.concatenate((np.ones(1), np.zeros(N - 1)))\n",
    "    zpk = sps.tf2zpk([1], a.ravel())\n",
    "    sos = sps.zpk2sos(*zpk)\n",
    "    res = sps.sosfilt(sos, x=u)\n",
    "    G = convm(res.ravel(), q + 1)\n",
    "    G0 = G[:N,].copy()\n",
    "    print(f\"{G0.shape=}\")\n",
    "    G0_H = np.transpose((G0.copy()).conjugate())\n",
    "    x0 = (x.copy()).reshape(-1, 1)\n",
    "    gx = G0_H @ x0\n",
    "    # the factorization does not guarantee nonsingularity!\n",
    "    # resulting matrix is positive *semi*-definite\n",
    "    Ginv = np.linalg.inv(G0_H @ G0)\n",
    "    print(f\"{x.shape=}\")\n",
    "    print(f\"{Ginv.shape=}\")\n",
    "    b = Ginv @ gx\n",
    "    err = 1\n",
    "\n",
    "    return a, b, err\n",
    "\n",
    "sig = np.ones(21)\n",
    "a, b, err = shanks(sig, 1, 1)\n",
    "print(f\"{a=}\")\n",
    "print(f\"{b=}\")\n",
    "print(f\"{err=}\")\n",
    "\n",
    "N = 81\n",
    "t = np.arange(N) - 5\n",
    "isys = 0.5 * np.sinc(t / 2)\n",
    "res = shanks(isys, 5, 5)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spike(g, n0, n):\n",
    "    '''Leaset Squares Inverse Filter'''\n",
    "\n",
    "    g = g.reshape(-1, 1)\n",
    "    m = len(g)\n",
    "\n",
    "    if m + n - 1 <= n0:\n",
    "        raise ValueError(f\"m + n - 1 must be less than {n0=}\")\n",
    "\n",
    "    G = convm(g, n)\n",
    "    d = np.zeros((m + n - 1, 1))\n",
    "    d[n0] = 1\n",
    "    print(f\"{d.shape=}, {G.shape=}\")\n",
    "    G_H = np.transpose(G.conjugate())\n",
    "\n",
    "    print(f\"{G_H.shape=}, {G.shape=}\")\n",
    "    Ginv = np.linalg.inv(G_H @ G)\n",
    "    h = Ginv @ G_H @ d\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09090909 0.18181818 0.27272727 0.36363636 0.45454545 0.54545455\n",
      " 0.63636364 0.72727273 0.81818182 0.90909091 1.         0.90909091\n",
      " 0.81818182 0.72727273 0.63636364 0.54545455 0.45454545 0.36363636\n",
      " 0.27272727 0.18181818 0.09090909]\n",
      "d.shape=(42, 1), G.shape=(42, 22)\n",
      "G_H.shape=(22, 42), G.shape=(42, 22)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2033e586550>]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 11\n",
    "ticks = (np.arange(N) + 1) / N\n",
    "ticks = np.concatenate((ticks, ticks[-2::-1]))\n",
    "print(ticks)\n",
    "h = spike(ticks, 3, 22)\n",
    "plt.plot(h, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ipf(x, p, q, n = 10, a = None):\n",
    "    pass\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      "  1. -1.]\n",
      "(array([[ 1.        ],\n",
      "       [-1.90933949],\n",
      "       [ 2.37404932],\n",
      "       [-1.95305779],\n",
      "       [ 1.0349931 ],\n",
      "       [-0.28932854]]), array([[ 0.06366198],\n",
      "       [-0.12278121],\n",
      "       [ 0.04903531],\n",
      "       [ 0.07290069],\n",
      "       [ 0.13450599],\n",
      "       [ 0.08350918]]), 1)\n",
      "Xq=array([[-1.,  1.],\n",
      "       [ 1., -1.],\n",
      "       [-1.,  1.],\n",
      "       [ 1., -1.],\n",
      "       [-1.,  1.],\n",
      "       [ 1., -1.],\n",
      "       [-1.,  1.],\n",
      "       [ 1., -1.],\n",
      "       [-1.,  1.],\n",
      "       [ 1., -1.],\n",
      "       [-1.,  1.],\n",
      "       [ 1., -1.],\n",
      "       [-1.,  1.],\n",
      "       [ 1., -1.],\n",
      "       [-1.,  1.],\n",
      "       [ 1., -1.],\n",
      "       [-1.,  1.],\n",
      "       [ 1., -1.]])\n",
      "Singular matrix, may indicate that model order can be reduced.\n"
     ]
    }
   ],
   "source": [
    "def acm(x, p) -> tuple[np.ndarray, np.ndarray]:\n",
    "    x0 = x.copy().ravel().reshape(-1, 1)\n",
    "    N = len(x0)\n",
    "    if p >= len(x0):\n",
    "        raise ValueError(\"p (all-pole model) too large\")\n",
    "\n",
    "    X = convm(x, p + 1)\n",
    "    Xq = X[:N + p - 1, :p].copy()\n",
    "    rx = X[1:N + p, 0].copy()\n",
    "    Xq_H = Xq.copy().conjugate().transpose()\n",
    "    Xinv = np.linalg.inv(Xq_H @ Xq)\n",
    "    a1 = -Xinv @ Xq_H @ rx\n",
    "    a = np.concatenate((np.ones(1), a1)).reshape(-1, 1)\n",
    "    err = np.abs(X[:N + p, 0].T @ X @ a)\n",
    "\n",
    "    return a, err\n",
    "\n",
    "def covm(x, p):\n",
    "    '''\n",
    "    Solve the complete Prony normal equations.\n",
    "    '''\n",
    "    x0 = x.copy().ravel().reshape(-1, 1)\n",
    "    N = len(x0)\n",
    "    if p >= len(x0):\n",
    "        raise ValueError(\"p (all-pole model) too large\")\n",
    "\n",
    "    X = convm(x0, p + 1)\n",
    "    Xq = X[p - 1:N - 1, :p].copy()\n",
    "    cx = X[p:N, 0].copy()\n",
    "    Xq_H = Xq.copy().conjugate().transpose()\n",
    "    print(f\"{Xq=}\")\n",
    "    Xinv = np.linalg.inv(Xq_H @ Xq)\n",
    "    a1 = -Xinv @ Xq_H @ cx\n",
    "    a = np.concatenate((np.ones(1), a1)).reshape(-1, 1)\n",
    "    err = np.abs(cx.transpose() @ X[p:N,] @ a)\n",
    "    return a, err\n",
    "\n",
    "sig = np.ones(20)\n",
    "sig[1::2] *= -1\n",
    "print(sig)\n",
    "a, err = acm(sig, 2)\n",
    "print(res)\n",
    "# b0 is the root of the least squared error - just a gain\n",
    "b = np.sqrt(err)\n",
    "\n",
    "try:\n",
    "    res = covm(sig, 2)\n",
    "except np.linalg.LinAlgError as exc:\n",
    "    print(\"Singular matrix, may indicate that model order can be reduced.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System State Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronynormal(x, p, q):\n",
    "    pass\n",
    "\n",
    "def ywe(x, p, q):\n",
    "    pass\n",
    "\n",
    "def mywe(x, p, q):\n",
    "    pass\n",
    "\n",
    "def eywe(x, p, q):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      "  1. -1.]\n",
      "[[1.  ]\n",
      " [0.95]] [[1.01240661]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def durbin(x, p, q):\n",
    "    x0 = x.copy().ravel().reshape(-1, 1)\n",
    "    N = len(x0)\n",
    "    if p >= len(x0):\n",
    "        raise ValueError(\"p (all-pole model) too large\")\n",
    "\n",
    "    a, eps = acm(x, p)\n",
    "    b, eps = acm(a / np.sqrt(eps), q)\n",
    "    b /= np.sqrt(eps)\n",
    "    return a, b\n",
    "\n",
    "sig = np.ones(20)\n",
    "sig[1::2] *= -1\n",
    "print(sig)\n",
    "a, err = durbin(sig, 1, 0)\n",
    "print(a, err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levinson Recursion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma=array([[-0.5]]),\n",
      "a=array([[ 1. ],\n",
      "       [-0.5]]),\n",
      "epsilon=array([[0.75]])\n",
      "\n",
      "gamma=array([[-0.33333333]]),\n",
      "a=array([[ 1.        ],\n",
      "       [-0.33333333],\n",
      "       [-0.33333333]]),\n",
      "epsilon=array([[0.66666667]])\n",
      "\n",
      "gamma=array([[0.125]]),\n",
      "a=array([[ 1.   ],\n",
      "       [-0.375],\n",
      "       [-0.375],\n",
      "       [ 0.125]]),\n",
      "epsilon=array([[0.65625]])\n",
      "\n",
      "(array([[ 1.   ],\n",
      "       [-0.375],\n",
      "       [-0.375],\n",
      "       [ 0.125]]), array([[0.65625]]))\n"
     ]
    }
   ],
   "source": [
    "def rtoa(r) -> tuple[np.ndarray, np.ndarray]:\n",
    "    '''\n",
    "    The Levison-Durbin recursion.\n",
    "    \"Recursive mapping from a set of autocorrelations to a set of model parameters.\"\n",
    "    '''\n",
    "\n",
    "    a = np.ones((1, 1))\n",
    "    epsilon = r[0]\n",
    "    p = len(r) - 1\n",
    "    r = r.reshape(-1, 1)\n",
    "\n",
    "    for j in range(1, p + 1):\n",
    "        gamma = -np.transpose(r[1:1 + j,]) @ np.flipud(a) / epsilon\n",
    "        an = np.concatenate((a, np.zeros((1, 1)))).reshape(-1, 1)\n",
    "        anT = np.conjugate(np.flipud(a))\n",
    "        a = an + gamma * np.concatenate(([0], anT.ravel())).reshape(-1, 1)\n",
    "        epsilon = epsilon * (1 - np.abs(gamma)**2)\n",
    "        print(f\"{gamma=},\\n{a=},\\n{epsilon=}\\n\")\n",
    "    return a, epsilon\n",
    "\n",
    "res = rtoa(np.array([1, 0.5, 0.5, 0.25]))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-Down and Step-Up Recursions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gtoa(gamma):\n",
    "    '''\n",
    "    Reference Page 233, Table 5.2, Figure 5.6\n",
    "    \"Step up recursion defines how model parameters for a jth-order\n",
    "    filter may be updated (stepped-up) to a (j + 1)st-order filter given reflection coefficients gamma.\"\n",
    "\n",
    "    Cumulant generating function in statistics.\n",
    "    '''\n",
    "\n",
    "    a = np.ones((1, 1))\n",
    "    p = len(gamma)\n",
    "    for j in range(1, p):\n",
    "        a = np.concatenate((a, np.zeros((1, 1))))\n",
    "        _a = a.copy()\n",
    "        af = np.conjugate(np.flipud(_a))\n",
    "        a = a + gamma[j] * af\n",
    "\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5]\n",
      " [ 0.2]\n",
      " [-0.5]]\n",
      "[[ 1.   ]\n",
      " [ 0.5  ]\n",
      " [-0.325]\n",
      " [-0.5  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.5],\n",
       "       [-0.1],\n",
       "       [-0.5]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def atog(a):\n",
    "    '''The step-down recursion.\n",
    "    \n",
    "    Used within the framework of the \"Shur-Cohn stability test\".\n",
    "    i.e., \"the roots of the polynomial will lie inside the unit circle if and only if the magnitudes of the reflection coefficients are less than 1.\n",
    "    i.e., the all-pole model/filter is minimum phase and guaranteed to be stable.\n",
    "\n",
    "    Mapping from reflection coefficients to filter coefficients.\n",
    "    '''\n",
    "\n",
    "    _a = np.array(a).reshape(-1, 1)\n",
    "    p = len(_a)\n",
    "    # drop a(0) and normalized in case it is not unity.\n",
    "    _a = _a[1:] / _a[0]\n",
    "\n",
    "\n",
    "    gamma = np.zeros((p - 1, 1))\n",
    "    gamma[p - 2] = _a[p - 2]\n",
    "\n",
    "    for j in range(p - 2, 0, -1):\n",
    "        #print(f\"{gamma=}, {_a=}\")\n",
    "        ai1 = _a[:j].copy()\n",
    "        ai2 = _a[:j].copy()\n",
    "        af = np.flipud(np.conjugate(ai1))\n",
    "        #print(f\"{ai1=}, {ai2=}, {af=}\")\n",
    "        s1 = ai2 - gamma[j] * af\n",
    "        s2 = 1 - np.abs(gamma[j])**2\n",
    "        _a = np.divide(s1, s2)\n",
    "        #print(f\"{s1=}, {s2=}, {_a=}\")\n",
    "        gamma[j - 1] = _a[j - 1]\n",
    "\n",
    "    return gamma\n",
    "\n",
    "# third order model\n",
    "a = [1, 0.5, -0.1, -0.5]\n",
    "gamma = atog(a)\n",
    "print(gamma)\n",
    "res = gtoa(a)\n",
    "print(res)\n",
    "atog(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Levinson-Durbin Recursions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75]\n",
      " [0.5 ]]\n",
      "[[-0.125]]\n",
      "(1, 1)\n",
      "[[ 1.  -0.5]]\n",
      "(1, 2)\n",
      "\n",
      "[[1.   ]\n",
      " [0.875]\n",
      " [0.5  ]]\n",
      "[[0.0625]]\n",
      "(1, 1)\n",
      "[[ 1.    -0.5   -0.125]]\n",
      "(1, 3)\n",
      "\n",
      "[[ 2.    -1.    -0.25   0.125]]\n"
     ]
    }
   ],
   "source": [
    "def gtor(gamma, epsilon=None):\n",
    "    '''\n",
    "    Finds the autocorrelation sequence from the reflection coefficients and the modeling error.\n",
    "    Page 241, Figure 5.9.\n",
    "    '''\n",
    "    p = len(gamma)\n",
    "    aa = np.array([[gamma[0]]]).reshape(-1, 1)\n",
    "    r = np.array(([1, -gamma[0]])).reshape(1, -1)\n",
    "\n",
    "    for j in range(1, p):\n",
    "        aa1 = np.concatenate((np.ones((1, 1)), aa)).reshape(-1, 1)\n",
    "        aa0 = np.concatenate((aa, np.zeros((1, 1)))).reshape(-1, 1)\n",
    "        aaf = np.conjugate(np.flipud(aa1))\n",
    "        aa = aa0 + gamma[j] * aaf\n",
    "        print(aa)\n",
    "        rf = -np.fliplr(r) @ aa\n",
    "        print(rf)\n",
    "        print(rf.shape)\n",
    "        print(r)\n",
    "        print(r.shape)\n",
    "        print()\n",
    "        r = np.concatenate((r[0], rf[0])).reshape(1, -1)\n",
    "\n",
    "    if epsilon is not None:\n",
    "        r = r * epsilon / np.prod(1 - np.abs(gamma)**2)\n",
    "\n",
    "    return r\n",
    "\n",
    "def test_gtor():\n",
    "    '''Based on example 5.2.6'''\n",
    "\n",
    "    gamma = [1/2, 1/2, 1/2]\n",
    "    epsilon = 2 * (3 / 4)**3\n",
    "    res = gtor(gamma, epsilon)\n",
    "    true_results = np.array([2, -1, -1/4, 1/8])\n",
    "    print(res)\n",
    "\n",
    "test_gtor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6]\n",
      " [0.2]]\n",
      "[[0.1]]\n",
      "(1, 1)\n",
      "[[ 1.  -0.5]]\n",
      "(1, 2)\n",
      "\n",
      "[[ 0.5]\n",
      " [-0.1]\n",
      " [-0.5]]\n",
      "[[0.4]]\n",
      "(1, 1)\n",
      "[[ 1.  -0.5  0.1]]\n",
      "(1, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def ator(a, b):\n",
    "    '''\n",
    "    Page 241, Figure 5.9.\n",
    "    '''\n",
    "\n",
    "    p = len(a) - 1\n",
    "    gamma = atog(a)\n",
    "    r = gtor(gamma.ravel())\n",
    "    r = r * np.sqrt(b) / np.prod(1 - np.abs(gamma)**2)\n",
    "\n",
    "    return r\n",
    "\n",
    "a = [1, 0.5, -0.1, -0.5]\n",
    "res = ator(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rtog(r):\n",
    "    '''\n",
    "    The Shur Recursion: Table 5.5\n",
    "    rtoa() then atog()'''\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "_r=array([[4],\n",
      "       [2],\n",
      "       [1]]), _r.shape=(3, 1)\n",
      "_r1=array([[2]]), _r1.shape=(1, 1)\n",
      "x=array([[2.25]]), x.shape=(1, 1)\n",
      "a=array([[1]]), a.shape=(1, 1)\n",
      "g=array([[2]]), g.shape=(1, 1)\n",
      "gamma=array([[-0.5]]), gamma.shape=(1, 1)\n",
      "_a0=array([[1],\n",
      "       [0]]), _a0.shape=(2, 1)\n",
      "_af=array([[0],\n",
      "       [1]]), _af.shape=(2, 1)\n",
      "epsilon=array([[3.]])\n",
      "\n",
      "2\n",
      "_r=array([[4],\n",
      "       [2],\n",
      "       [1]]), _r.shape=(3, 1)\n",
      "_r1=array([[2, 1]]), _r1.shape=(1, 2)\n",
      "x=array([[2. ],\n",
      "       [0.5]]), x.shape=(2, 1)\n",
      "a=array([[ 1. ],\n",
      "       [-0.5]]), a.shape=(2, 1)\n",
      "g=array([[0.]]), g.shape=(1, 1)\n",
      "gamma=array([[-0.]]), gamma.shape=(1, 1)\n",
      "_a0=array([[ 1. ],\n",
      "       [-0.5],\n",
      "       [ 0. ]]), _a0.shape=(3, 1)\n",
      "_af=array([[ 0. ],\n",
      "       [-0.5],\n",
      "       [ 1. ]]), _af.shape=(3, 1)\n",
      "epsilon=array([[3.]])\n",
      "\n",
      "[[ 2.]\n",
      " [-1.]\n",
      " [ 3.]]\n"
     ]
    }
   ],
   "source": [
    "def glev(r, b):\n",
    "    '''General Levinson Recursion, solves any Hermitian Toeplitz matrix.\n",
    "\n",
    "    Can solve the Wiener-Hopf system of equations for Optimal MSE Filter design.\n",
    "    '''\n",
    "\n",
    "    _r = np.array(r).reshape(-1, 1)\n",
    "    _b = np.array([b]).reshape(-1, 1)\n",
    "    p = len(b)\n",
    "    a = np.array([[1]]).reshape(-1, 1)\n",
    "    x = np.array([b[0] / r[0]]).reshape(-1, 1)\n",
    "    epsilon = r[0]\n",
    "    for j in range(1, p):\n",
    "        print(j)\n",
    "        print(f\"{_r=}, {_r.shape=}\")\n",
    "        _r1 = np.transpose(np.array(_r[1:j + 1]))\n",
    "        print(f\"{_r1=}, {_r1.shape=}\")\n",
    "        print(f\"{x=}, {x.shape=}\")\n",
    "        print(f\"{a=}, {a.shape=}\")\n",
    "        g = _r1 @ np.flipud(a)\n",
    "        print(f\"{g=}, {g.shape=}\")\n",
    "        gamma = -g / epsilon\n",
    "        print(f\"{gamma=}, {gamma.shape=}\")\n",
    "        _a0 = np.concatenate([a, [[0]]])\n",
    "        _af = np.conjugate(np.flipud(_a0))\n",
    "        print(f\"{_a0=}, {_a0.shape=}\")\n",
    "        print(f\"{_af=}, {_af.shape=}\")\n",
    "        a = _a0 + gamma * _af\n",
    "        epsilon = epsilon * (1 - np.abs(gamma)**2)\n",
    "        print(f\"{epsilon=}\")\n",
    "        delta = _r1 @ np.flipud(x)\n",
    "        q = (b[j] - delta[0, 0]) / epsilon\n",
    "        _x0 = np.concatenate([x, [[0]]])\n",
    "        x = _x0 + q * np.conjugate(np.flipud(a))\n",
    "        print()\n",
    "\n",
    "    return x\n",
    "\n",
    "def test_glev():\n",
    "    '''Example 5.3.1, Page 266'''\n",
    "    r = [4, 2, 1]\n",
    "    b = [9, 6, 12]\n",
    "\n",
    "    res = glev(r, b)\n",
    "    print(res)\n",
    "\n",
    "test_glev()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Shur-Cohn Stability Test\n",
    "\n",
    "For any linear shift-invariant system defined in a rational form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lattice Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[-0.97521982]\n",
      " [-1.        ]\n",
      " [ 3.        ]]\n",
      "[[9.49795719e-04]\n",
      " [1.00000000e+00]\n",
      " [3.00000000e+00]]\n",
      "\n",
      "1\n",
      "[[-0.97521982]\n",
      " [ 0.07886059]\n",
      " [ 3.        ]]\n",
      "[[9.49795719e-04]\n",
      " [8.51807218e-04]\n",
      " [3.00000000e+00]]\n",
      "\n",
      "2\n",
      "[[-0.97521982]\n",
      " [ 0.07886059]\n",
      " [ 0.00460021]]\n",
      "[[0.0009498 ]\n",
      " [0.00085181]\n",
      " [0.00082163]]\n",
      "\n",
      "(array([[-0.97521982],\n",
      "       [ 0.07886059],\n",
      "       [ 0.00460021]]), array([[0.0009498 ],\n",
      "       [0.00085181],\n",
      "       [0.00082163]]))\n"
     ]
    }
   ],
   "source": [
    "def fcov(x, p):\n",
    "    '''\n",
    "    Figure 6.15, Page 310.\n",
    "\n",
    "    Using the forward covariance method the reflection co-efficients of the lattice filter\n",
    "    are found by sequentially minimizing the sum of the squares of the forward prediction error. \n",
    "    '''\n",
    "\n",
    "    if p >= len(x):\n",
    "        raise ValueError(\"Model order must be less than length of signal\")\n",
    "\n",
    "    _x = np.array(x).reshape(-1, 1)\n",
    "    N = len(x)\n",
    "    eplus = _x[1:N]\n",
    "    eminus = _x[:N - 1]\n",
    "\n",
    "    gamma = np.empty((p, 1))\n",
    "    err = np.empty((p, 1))\n",
    "\n",
    "    for j in range(p):\n",
    "        print(j)\n",
    "        N = N - 1\n",
    "        #print(f\"{eplus=}, {eplus.shape=}\")\n",
    "        #print(f\"{eminus=}, {eminus.shape=}\")\n",
    "        gamma[j] = (np.transpose(-eminus) @ eplus) / (np.transpose(eminus) @ eminus)\n",
    "        temp1 = eplus + gamma[j] * eminus\n",
    "        temp2 = eminus + np.conjugate(gamma[j]) * eplus\n",
    "        err[j] = np.transpose(temp1) @ temp1\n",
    "        eplus = temp1[1:N]\n",
    "        eminus = temp2[:N - 1]\n",
    "        print(gamma)\n",
    "        print(err)\n",
    "        print()\n",
    "\n",
    "    return gamma, err\n",
    "\n",
    "N = 60\n",
    "sig = np.ones(N) / 4\n",
    "sig = np.arange(N, 0, -1) / N / 2\n",
    "res = fcov(sig, 3)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 1.00000000e+00,  4.93865927e-01, -3.89910326e-13, -1.50613407e+00]),\n",
       " -0.0632362105058295)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def burg(x, p):\n",
    "    '''\n",
    "    Sequentially minimizes the sum of the forward and backward covariance errors.\n",
    "\n",
    "    Guaranteed to be stable. All reflection coefficients will be <|1|\n",
    "    '''\n",
    "\n",
    "    if p > len(x):\n",
    "        raise ValueError(\"Model order must be less than length of signal\")\n",
    "\n",
    "    _x = np.array(x).reshape(-1, 1)\n",
    "    N = len(x)\n",
    "    eplus = _x[1:N]\n",
    "    eminus = _x[:N - 1]\n",
    "\n",
    "    gamma = np.empty((p, 1))\n",
    "    err = np.empty((p, 1))\n",
    "\n",
    "    for j in range(p):\n",
    "        print(j)\n",
    "        N = N - 1\n",
    "        #print(f\"{eplus=}, {eplus.shape=}\")\n",
    "        #print(f\"{eminus=}, {eminus.shape=}\")\n",
    "        eplusmag = (np.transpose(eplus) @ eplus)\n",
    "        eminusmag = (np.transpose(eplus) @ eplus)\n",
    "        gamma[j] = (np.transpose(-2 * eminus) @ eplus) / (eplusmag + eminusmag)\n",
    "        temp1 = eplus + gamma[j] * eminus\n",
    "        temp2 = eminus + np.conjugate(gamma[j]) * eplus\n",
    "        err[j] = np.transpose(temp1) @ temp1 + np.transpose(temp2) @ temp2\n",
    "        eplus = temp1[1:N]\n",
    "        eminus = temp2[:N - 1]\n",
    "        print()\n",
    "\n",
    "    return gamma, err\n",
    "\n",
    "\n",
    "def bcov(x, p):\n",
    "    '''\n",
    "    Sequentially minimizes the backward covariance error.\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "def mcov(x, p):\n",
    "    '''\n",
    "    Modified covariance method. Unlike the forward/backward algorithms,\n",
    "    it *does not* minimize an error term sequentially.\n",
    "    '''\n",
    "    _x = np.array(x).reshape(-1, 1)\n",
    "    N = len(x)\n",
    "\n",
    "    if p >= len(x):\n",
    "        raise ValueError(\"Model order must be less than length of signal\")\n",
    "\n",
    "    X = sp.linalg.toeplitz(_x[p:N], np.flipud(x[:p + 1]))\n",
    "    R = np.transpose(X) @ X\n",
    "    R1 = np.array(R[1:p + 1, 1: p + 1])\n",
    "    R2 = np.array(np.flipud(np.fliplr(R[:p, :p])))\n",
    "    b1 = np.array(R[1:p + 1, 1])\n",
    "    b2 = np.array(np.flipud(R[:p, p]))\n",
    "\n",
    "    Rx = -R1 - R2\n",
    "    b = b1 + b2\n",
    "    a = sp.linalg.solve_toeplitz(Rx[:, 1], b)\n",
    "    a = np.concatenate(([1], a))\n",
    "    print(a.shape)\n",
    "    err = np.dot(R[0], a) + np.dot(np.flip(R[p]), a)\n",
    "\n",
    "    return a, err\n",
    "\n",
    "sig = np.flip(np.arange(60) / N / 2)\n",
    "mcov(sig, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimum Filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoiser_wiener_fir(x, v):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman(x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodogram(x):\n",
    "    pass\n",
    "\n",
    "def overlay(N, omega, A, sigma, num):\n",
    "    '''Calculates the periodogram using an ensemble of realizations'''\n",
    "    pass\n",
    "\n",
    "def mper(x, win, n1, n2):\n",
    "    '''Modified Periodogram'''\n",
    "    pass\n",
    "\n",
    "def bart(x, nsect):\n",
    "    '''Bartlett method of non-paramteric spectrum estimation'''\n",
    "    pass\n",
    "\n",
    "def welch(x, L, over, win):\n",
    "    pass\n",
    "\n",
    "def per_smooth(x, win, M, n1, n2):\n",
    "    '''Blackman-Tukey method of non-parametric spectrum estimation'''\n",
    "    pass\n",
    "\n",
    "def minvar(x, p):\n",
    "    '''Minimum Variance spectrum estimation'''\n",
    "    pass\n",
    "\n",
    "def mem(x, p):\n",
    "    '''Maximum Entropy spectrum estimation'''\n",
    "    pass\n",
    "\n",
    "def modebased(x, p, q):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phd(x, p):\n",
    "    '''Pisarenko Harmonic Decomposition'''\n",
    "    pass\n",
    "\n",
    "def music(x, p, M):\n",
    "    pass\n",
    "\n",
    "def min_norm(x, p, M):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principle Component Analysis (PCA) Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_bt(x, p, M):\n",
    "    pass\n",
    "\n",
    "def pca_mv(x, p, M):\n",
    "    pass\n",
    "\n",
    "def pca_mem(x, p, M):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lms(x, d, mu, nord, a0):\n",
    "    '''LMS Adaptive Filter'''\n",
    "    pass\n",
    "\n",
    "def nlms(x, d, mu, nord, a0):\n",
    "    '''Normalized LMS Adaptive Filter'''\n",
    "    pass\n",
    "\n",
    "def rls(x, d, lamda, nord):\n",
    "    '''Recursive Least Squares'''\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
